# -*- coding: utf-8 -*-
"""HW1.2_108034022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Eln_kCZhLvJ8xJ39BEKt0BQCgF-IFxG
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import math
import scipy
from scipy import signal
from os import listdir
from numpy.linalg import eig

from google.colab import drive
drive.mount('/content/drive')

def interestPointDetection(img1, img2, nfeatures, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6):
  # create SIFT detector
  sift = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures, nOctaveLayers=nOctaveLayers, contrastThreshold=contrastThreshold, edgeThreshold=edgeThreshold, sigma=sigma)
  # detect
  keypoints1, features1 = sift.detectAndCompute(img1, None)
  keypoints2, features2 = sift.detectAndCompute(img2, None)
  # draw keypoints
  detect1 = cv2.drawKeypoints(image=img1, outImage=img1, keypoints=keypoints1, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS, color=(0, 0, 255))
  detect2 = cv2.drawKeypoints(image=img2, outImage=img2, keypoints=keypoints2, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS, color=(0, 255, 0))
  
  concat = np.hstack# concatenate two images([detect1, detect2])
  return concat, keypoints1, features1, keypoints2, features2

img1 = cv2.imread('/content/drive/MyDrive/CV_HW1/B/original/1a_notredame.jpg')
h, w = img1.shape[:2]
img2 = cv2.imread('/content/drive/MyDrive/CV_HW1/B/original/1b_notredame.jpg')
img2 = cv2.resize(img2, (w, h))
detect, kps1, fea1, kps2, fea2 = interestPointDetection(img1, img2, 500, 5, 0.08, 8, 3.0)

cv2.imwrite('detection.jpg', detect)

def oneNN_FeatureMatching(img1, img2, kps1, kps2, fea1, fea2, threshold):
  # initialization, idxMatching[kpj] = [difference between kpi and kpj, kpi]
  idxMatching = [[np.inf, -1]] * len(fea2)
  
  for i in range(len(fea1)): # traverse interest points in img1
    match = [-1, np.inf] 
    for j in range(len(fea2)):
      diff = np.linalg.norm(fea1[i] - fea2[j]) # calculate the distance of two points
      if diff < match[1]: # match keypoints i in img1 with keypoints j in img2 having the shortest distance from keypoints i
        match = [j, diff]
    
    if match[1] < threshold: # filter out poorly related pairs with threshold
      if idxMatching[match[0]][0] > match[1]: # each keypoint in img2 can be matched with at most one keypoint in img1     
        idxMatching[match[0]] = [match[1], i]
  
  # get coordinates of matched interest points and draw them
  h, w = img1.shape[:2]
  pointMatching = []
  for j in range(len(idxMatching)):
    if idxMatching[j][0] != -1:
      pointA = (int(kps1[idxMatching[j][1]].pt[0]), int(kps1[idxMatching[j][1]].pt[1]))
      pointB = (w + int(kps2[j].pt[0]), int(kps2[j].pt[1]))
      pointMatching.append([pointA, pointB])
    
  
  concat = np.hstack([img1, img2])
  for (pointA, pointB) in pointMatching:
    cv2.circle(concat, pointA, 4, (0, 0, 255), 3)
    cv2.circle(concat, pointB, 4, (0, 255, 0), 3)
    cv2.line(concat, pointA, pointB, (0, 0, 0), 2)

  return concat, pointMatching

img1 = cv2.imread('/content/drive/MyDrive/CV_HW1/B/original/1a_notredame.jpg')
h, w = img1.shape[:2]
img2 = cv2.imread('/content/drive/MyDrive/CV_HW1/B/original/1b_notredame.jpg')
img2 = cv2.resize(img2, (w, h))
threshold = 240
matching, points = oneNN_FeatureMatching(img1, img2, kps1, kps2, fea1, fea2, threshold)
cv2.imwrite("./1NN_matching.jpg", matching)

def twoNN_FeatureMatching(img1, img2, kps1, kps2, fea1, fea2, threshold, ratio):
  idxMatching = [[np.inf, -1, -1]] * len(fea2) #idxMatching[i] = [difference between kpi and kpj, kpi, kpj]
  for i in range(len(fea1)):
    # two canditates for 2 nearest neighbor algorithm
    minDiff = [-1, np.inf]
    secMinDiff = [-1, np.inf]
    for j in range(len(fea2)):
      diff = np.linalg.norm(fea1[i] - fea2[j])
      if diff < minDiff[1]: # update minDiff if keypoints2[j] has shorter distance from keypoints1[i]
        secMinDiff = minDiff
        minDiff = [j, diff]
      elif diff < secMinDiff[1]: # update secMinDiff
        secMinDiff = [j, diff]
    
    
    if minDiff[1] < secMinDiff[1] * ratio and minDiff[1] < threshold: # use 2NN method to check whether kps1[i] and kps2[minDiff] can be matched and # filter out poorly related pairs with threshold
      if idxMatching[minDiff[0]][0] > minDiff[1]: # each keypoint in img2 can be matched with at most one keypoint in img1
        idxMatching[minDiff[0]] = [minDiff[1], i, minDiff[0]]

  # get coordinates of matched interest points and draw them
  h, w = img1.shape[:2]
  pointMatching = []
  for (diff, idA, idB) in idxMatching:
    pointA = (int(kps1[idA].pt[0]), int(kps1[idA].pt[1]))
    pointB = (w + int(kps2[idB].pt[0]), int(kps2[idB].pt[1]))
    pointMatching.append([pointA, pointB])

  concat = np.hstack([img1, img2])
  for (pointA, pointB) in pointMatching:
    cv2.circle(concat, pointA, 4, (0, 0, 255), 3)
    cv2.circle(concat, pointB, 4, (0, 255, 0), 3)
    cv2.line(concat, pointA, pointB, (0, 0, 0), 2)

  return concat, pointMatching

threshold = 240
ratio = 0.85
matching2, points2 = twoNN_FeatureMatching(img1, img2, kps1, kps2, fea1, fea2, threshold, ratio)
cv2.imwrite('./2NN_matching.jpg', matching2)